<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Tutorial &mdash; pysmc 0.0 documentation</title>
    
    <link rel="stylesheet" href="_static/pyramid.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="pysmc 0.0 documentation" href="index.html" />
    <link rel="next" title="Reference" href="reference.html" />
    <link rel="prev" title="Installation" href="install.html" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Neuton&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Nobile:regular,italic,bold,bolditalic&amp;subset=latin" type="text/css" media="screen" charset="utf-8" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

  </head>
  <body>

    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="reference.html" title="Reference"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="install.html" title="Installation"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">pysmc 0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="tutorial">
<span id="id1"></span><h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>Before moving forward, make sure you understand:</p>
<blockquote>
<div><ul class="simple">
<li>What is probability? That&#8217;s a big question... If you feel like it,
I suggest you skim through <a class="reference external" href="E.T.Jaynes'http://en.wikipedia.org/wiki/Edwin_Thompson_Jaynes&gt;">E. T. Jaynes</a>&#8216;s book
<a class="reference external" href="http://omega.albany.edu:8008/JaynesBook.html">Probability Theory: The Logic of Science</a>.</li>
<li>What is <a class="reference external" href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a>?</li>
<li>Read the tutorial of <a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a>.
To the very least, you need to be able to construct probabilistic
models using this package. For advanced applications, you need to be
able to construct your own <a class="reference external" href="http://pymc-devs.github.io/pymc/extending.html#user-defined-step-methods">MCMC step methods</a>.</li>
<li>Of course, I have to assume some familiarity with the so called
Sequential Monte Carlo (SMC) or Particle Methods. Many resources can
be found online at <a class="reference external" href="http://www.stats.ox.ac.uk/~doucet/smc_resources.html">Arnaud Doucet&#8217;s collection</a> or in his book
<a class="reference external" href="http://books.google.com/books/about/Sequential_Monte_Carlo_Methods_in_Practi.html?id=BnWAcgAACAAJ">Sequential Monte Carlo Methods in Practice</a>. What exactly <a class="reference internal" href="reference.html#module-pysmc" title="pysmc: The main PySMC module."><tt class="xref py py-mod docutils literal"><span class="pre">pysmc</span></tt></a>
does is documented in <a class="reference internal" href="math.html#math"><em>Mathematical Details</em></a>.</li>
</ul>
</div></blockquote>
<div class="section" id="what-is-sequential-monte-carlo">
<span id="what-is-smc"></span><h2>What is Sequential Monte Carlo?<a class="headerlink" href="#what-is-sequential-monte-carlo" title="Permalink to this headline">¶</a></h2>
<p>Sequential Monte Carlo (SMC) is a very efficient and effective way to sample
from complicated probability distributions known up to a normalizing constant.
The most important complicating factor is multi-modality. That is, probability
distributions that do not look at all like Gaussians.</p>
<p>The complete details can be found in <a class="reference internal" href="math.html#math"><em>Mathematical Details</em></a>. However, let us give some
insights on what is really going on. Assume that we want so sample
from a probability distribution <img class="math" src="_images/math/2751d79d3bbfb34440d68c685fe6ba7414951749.png" alt="p(x)"/>, known up to a normalizing
constant:</p>
<div class="math">
<p><img src="_images/math/526efd5bf392da9a76815b6708a67b8e69943a55.png" alt="p(x) \propto \pi(x)."/></p>
</div><p>Normally, we construct a variant of <a class="reference external" href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> to sample from this
distribution. If <img class="math" src="_images/math/2751d79d3bbfb34440d68c685fe6ba7414951749.png" alt="p(x)"/> is multi-modal, it is certain that the Markov
Chain will get attracted to one of the modes. Theoretically, if the modes are
connected, it is guaranteed that they will all be visited
<em>as the number of MCMC steps goes to infinity</em>. However, depending on the
probability of the paths that connect the modes, the chain might
never escape during the finite number of MCMC steps that we can actually afford
to perform.</p>
<p>SMC attempts to alleviate this problem. The way it does it is similar to the
ideas found in <a class="reference external" href="http://en.wikipedia.org/wiki/Simulated_annealing">Simulated Annealing</a>. The user defines a family of probability
densities:</p>
<div class="math" id="equation-smc_sequence">
<p><span class="eqno">(1)</span><img src="_images/math/6f6f41702921974186c4f508c26f338c065b87a7.png" alt="p_{i}(x) \propto \pi_{i}(x),\;i=1,\dots,n,"/></p>
</div><p>such that:</p>
<ul class="simple">
<li>it is easy to sample from <img class="math" src="_images/math/4a29013872ed0ff1a9f999ba95e3b15f77987305.png" alt="p_0(x)"/> (either directly or using MCMC),</li>
<li>the probability densities <img class="math" src="_images/math/d01a5e1284bc27a1fcf7644fc809bf7fcd57e07e.png" alt="p_i(x)"/> and <img class="math" src="_images/math/87d43b4f678e6c136a2d30b22f8809b6e6661fda.png" alt="p_{i+1}(x)"/> are
<em>similar</em>,</li>
<li>the last probability density of the sequence is the target, i.e.,
<img class="math" src="_images/math/1db5a074db30cdc65e15f957f78713b5af375370.png" alt="p_n(x) = p(x)"/>.</li>
</ul>
<p>There are many ways to define such a sequence. Usually, the exact sequence that
needs to be followed is obvious from the definition of the problem. An obvious
choice is:</p>
<div class="math" id="equation-smc_sequence_power">
<p><span class="eqno">(2)</span><img src="_images/math/da0eec7d3663cc53e1a2ea612a57da6e15f8cc1f.png" alt="p_i(x) \propto \pi^{\gamma_i}(x),\;i=1,\dots,n,"/></p>
</div><p>where <img class="math" src="_images/math/cbe065ef1957f1cfa20281d4ea41ba2cbb716906.png" alt="\gamma_0"/> is a non-negative number that makes <img class="math" src="_images/math/d01a5e1284bc27a1fcf7644fc809bf7fcd57e07e.png" alt="p_i(x)"/> look
flat (e.g., if <img class="math" src="_images/math/2751d79d3bbfb34440d68c685fe6ba7414951749.png" alt="p(x)"/> has a compact support, you may choose
<img class="math" src="_images/math/ef3255117935737801b2f36f56229543c14d6661.png" alt="\gamma_0=0"/> which makes <img class="math" src="_images/math/4a29013872ed0ff1a9f999ba95e3b15f77987305.png" alt="p_0(x)"/> the uniform density. For
the general case a choice like <img class="math" src="_images/math/f353837cbc9eb0a9e51c7797f89789157f27da5a.png" alt="\gamma_0=10^{-3}"/> would still do a good
job) and <img class="math" src="_images/math/cd5348142d33fad94987944d612831221cff8c05.png" alt="\gamma_n=1"/>. If <img class="math" src="_images/math/174fadd07fd54c9afe288e96558c92e0c1da733a.png" alt="n"/> is chosen sufficiently large and
<img class="math" src="_images/math/364de412771666b0ec178af3e30405e5a9acf00c.png" alt="gamma_i &lt; \gamma_{i+1}"/> then indeed <img class="math" src="_images/math/d01a5e1284bc27a1fcf7644fc809bf7fcd57e07e.png" alt="p_i(x)"/> and <img class="math" src="_images/math/87d43b4f678e6c136a2d30b22f8809b6e6661fda.png" alt="p_{i+1}(x)"/>
will look similar.</p>
<p>Now we are in a position to discuss what SMC does. We represent each one of the
probability densities <img class="math" src="_images/math/d01a5e1284bc27a1fcf7644fc809bf7fcd57e07e.png" alt="p_i(x)"/>
<a href="#equation-smc_sequence">(1)</a> with a <em>particle approximation</em>
<img class="math" src="_images/math/1622a3852cd408d697e353a2bf6e2fc64f4ade49.png" alt="\left\{\left(w^{(j)_i}, x^{(j)_i}\right)\right\}_{j=1}^N"/>, where:</p>
<ul class="simple">
<li><img class="math" src="_images/math/fc97ef67268cd4e91bacdf12b8901d7036c9a056.png" alt="N"/> is known as the <em>number of particles</em>,</li>
<li><img class="math" src="_images/math/872213fa4d9801acbcb88cf0be40e4312aa7cf08.png" alt="w^{(j)}_i"/> is known as the <em>weight</em> of particle <img class="math" src="_images/math/8122aa89ea6e80784c6513d22787ad86e36ad0cc.png" alt="j"/>
(normalized so that <img class="math" src="_images/math/e3202823b5b2b0a351f297aa39ef39927ec379b7.png" alt="\sum_{j=1}^Nw^{(j)}_i=1"/>),</li>
<li><img class="math" src="_images/math/fd0e16ca512a3e8f94af59372b1734a902262df3.png" alt="x^{(j)}_i"/> is known as the <em>particle</em> <img class="math" src="_images/math/8122aa89ea6e80784c6513d22787ad86e36ad0cc.png" alt="j"/>.</li>
</ul>
<p>Typically we write:</p>
<div class="math" id="equation-smc_approx">
<p><span class="eqno">(3)</span><img src="_images/math/598a8d19f660c29a521aabca2c59f3e3da89ed08.png" alt="p_i(x) \approx \sum_{j=1}^Nw^{(j)}_i\delta\left(x - x^{(j)}_i\right),"/></p>
</div><p>but what we really mean is that for any measurable
function of the state space <img class="math" src="_images/math/c96dd6ec1dc4ad7520fbdc78fcdbec9edd068d0c.png" alt="f(x)"/> the following holds:</p>
<div class="math" id="equation-smc_approx_def">
<p><span class="eqno">(4)</span><img src="_images/math/10abb434b50a7695a4a9f281b9fff69214dd6f98.png" alt="\lim_{N\rightarrow\infty}\sum_{j=1}^Nw_i^{(j)}f\left(x^{(j)}_i\right) = \
\int f(x) p_i(x)dx,"/></p>
</div><p>almost surely.</p>
<p>So far so good. The only issue here is actually constructing a particle
approximation satisfying <a href="#equation-smc_approx_def">(4)</a>. This is a little bit involved
and thus described in <a class="reference internal" href="math.html#math"><em>Mathematical Details</em></a>. Here it suffices to say that it more or less
goes like this:</p>
<ol class="arabic simple">
<li>Start with <img class="math" src="_images/math/3468ccd41bc761dcc455140089e3224a4b1b95e3.png" alt="i=0"/> (i.e., the easy to sample distribution).</li>
<li>Sample <img class="math" src="_images/math/c5effa19b9855b72861b1aad4143859001e3884f.png" alt="x_0^{(j)}"/> from <img class="math" src="_images/math/4a29013872ed0ff1a9f999ba95e3b15f77987305.png" alt="p_0(x)"/> either directly (if possible) or
using MCMC and set the weights equal to <img class="math" src="_images/math/8f1c821a6c139bb8477adbaa1654efb7b8e2817c.png" alt="w_0^{(j)} = 1 / N"/>. Then
<a href="#equation-smc_approx_def">(4)</a> is satisfied for <img class="math" src="_images/math/3468ccd41bc761dcc455140089e3224a4b1b95e3.png" alt="i=0"/>.</li>
<li>Compute the weights <img class="math" src="_images/math/98c8a062537ac6bc54f2d4b0ec37d5d62166545f.png" alt="w_{i+1}(j)"/> and sample -using an appropriate MCMC
kernel- the particles of the next step <img class="math" src="_images/math/408043e73344fb357d3dd0abd02adfca27708e89.png" alt="x_i^{(j+1)}"/> so that they
corresponding particle approximation satisfies <a href="#equation-smc_approx_def">(4)</a>.</li>
<li>Set <img class="math" src="_images/math/7be4738bc61dd87181701c9469fafe182e4d8604.png" alt="i=i+1"/>.</li>
<li>If <img class="math" src="_images/math/801b4b6c57a1e85c609e277fa66555060aacd29f.png" alt="i=n"/> stop. Otherwise go to 3.</li>
</ol>
</div>
<div class="section" id="what-is-implemented-in-pysmc">
<span id="what-is-in-pysmc"></span><h2>What is implemented in <a class="reference internal" href="reference.html#module-pysmc" title="pysmc: The main PySMC module."><tt class="xref py py-mod docutils literal"><span class="pre">pysmc</span></tt></a>?<a class="headerlink" href="#what-is-implemented-in-pysmc" title="Permalink to this headline">¶</a></h2>
<p><a class="reference internal" href="reference.html#module-pysmc" title="pysmc: The main PySMC module."><tt class="xref py py-mod docutils literal"><span class="pre">pysmc</span></tt></a> implements something a little bit more complicated than what is
described in <a class="reference internal" href="#what-is-smc"><em>What is Sequential Monte Carlo?</em></a>. The full description can be found in
<a class="reference internal" href="math.html#math"><em>Mathematical Details</em></a>. Basically, we assume that the user has defined a one-parameter
family of probability densities:</p>
<div class="math" id="equation-p_gamma">
<p><span class="eqno">(5)</span><img src="_images/math/25eb4344cfbbf657a399dcd55a32062f8aa12759.png" alt="p_{\gamma}(x) \propto \pi_{\gamma}(x)."/></p>
</div><p>The code must be initialized with a particle approximation at a desired value
of <img class="math" src="_images/math/4ece42902a35d5def1b35b4c4b9dd6cf8be65477.png" alt="\gamma=\gamma_0"/>. This can be done either manually by the user or
automatically by <a class="reference internal" href="reference.html#module-pysmc" title="pysmc: The main PySMC module."><tt class="xref py py-mod docutils literal"><span class="pre">pysmc</span></tt></a> (e.g. by direct sampling or MCMC).
Having constructed an initial particle approximation, the code can be instructed
to move it to another <img class="math" src="_images/math/e9842b3a541c8e8ed65cea6742ac6a3b12628076.png" alt="\gamma=\gamma_1"/>. If the two probability densities
<img class="math" src="_images/math/1ddf9402cd7168374aad5ad710e30b47dd2cc71b.png" alt="p_{\gamma_0}(x)"/> and <img class="math" src="_images/math/4e9033b0682735fab12efb31aba6aa4ee6391fa9.png" alt="p_{\gamma_1}(x)"/> are close, then the code
will jump directly into the construction of the particle approximation at
<img class="math" src="_images/math/e9842b3a541c8e8ed65cea6742ac6a3b12628076.png" alt="\gamma=\gamma_1"/>. If not, then it will adaptively construct a finite
sequence of <img class="math" src="_images/math/66981fa3920210c6ad8dbe5e968783d5dd7520c3.png" alt="\gamma"/>&#8216;s connecting <img class="math" src="_images/math/cbe065ef1957f1cfa20281d4ea41ba2cbb716906.png" alt="\gamma_0"/> and <img class="math" src="_images/math/24746dfd17e9188871007307efc793c9be692647.png" alt="\gamma_1"/>
and jump from one to the other. Therefore, the user only needs to specify:</p>
<ul class="simple">
<li>the initial, easy-to-sample-from probability density,</li>
<li>the target density,</li>
<li>a one-parametric family of densities that connect the two.</li>
</ul>
<p>We will see how this can be achieved through a bunch of examples.</p>
</div>
<div class="section" id="a-simple-example">
<span id="simple-example"></span><h2>A Simple Example<a class="headerlink" href="#a-simple-example" title="Permalink to this headline">¶</a></h2>
<p>We will start with a probability density with two modes, namely a mixture of
two normal densities:</p>
<div class="math" id="equation-simple_model_pdf">
<p><span class="eqno">(6)</span><img src="_images/math/3cbd4306226852701e87113cf7648570771d4e0a.png" alt="p(x) = \pi_1 \mathcal{N}\left(x | \mu_1, \sigma_1^2 \right) + \
       \pi_2 \mathcal{N}\left(x | \mu_2, \sigma_2^2 \right),"/></p>
</div><p>where <img class="math" src="_images/math/7decedc0d204a364237a8b09cab3468248745b85.png" alt="\mathcal{N}(x|\mu, \sigma^2)"/> denotes the probability density of a
normal random variable with mean <img class="math" src="_images/math/2d8c833ed800824727cd7bd2fb9de1a12ad7e674.png" alt="\mu"/> and variance <img class="math" src="_images/math/741fb9098efcb98055f467f87630a5d0ca599b6b.png" alt="\sigma^2"/>.
<img class="math" src="_images/math/4cfa39c27650e228f277bfe4faa40f2033ffa79e.png" alt="\pi_i&gt;0"/> is the weight given to the <img class="math" src="_images/math/34857b3ba74ce5cd8607f3ebd23e9015908ada71.png" alt="i"/>-th normal
(<img class="math" src="_images/math/be15f39a27d2b8d2c9f17407f0c77c057da19e19.png" alt="\pi_1 + \pi_2 = 1"/>) and <img class="math" src="_images/math/ca3062c7ebb8b9a8aa932725e31ea4c7800515fd.png" alt="\mu_i, \sigma_i^2"/> are the corresponding
mean and variance. We pick the following parameters:</p>
<ul class="simple">
<li><img class="math" src="_images/math/e0f2f6686933cfeacd7df6b553a53e5e490fb09f.png" alt="\pi_1=0.2, \mu_1=-1, \sigma_1=0.01"/>,</li>
<li><img class="math" src="_images/math/a3fc4aa6f7ba93dd8bba574496db826a6bd2f545.png" alt="\pi_2=0.8, \mu_2=2, \sigma_2=0.01"/>.</li>
</ul>
<p>This probability density is shown in <a class="reference internal" href="#simple-example-pdf-figure">Simple Example PDF Figure</a>. It is obvious
that sampling this probability density using MCMC will be very problematic.</p>
<div class="figure align-center" id="simple-example-pdf-figure">
<img alt="_images/simple_model_pdf.png" src="_images/simple_model_pdf.png" />
<p class="caption">Plot of <a href="#equation-simple_model_pdf">(6)</a> with
<img class="math" src="_images/math/e0f2f6686933cfeacd7df6b553a53e5e490fb09f.png" alt="\pi_1=0.2, \mu_1=-1, \sigma_1=0.01"/> and
<img class="math" src="_images/math/a3fc4aa6f7ba93dd8bba574496db826a6bd2f545.png" alt="\pi_2=0.8, \mu_2=2, \sigma_2=0.01"/>.</p>
</div>
<div class="section" id="defining-a-family-of-probability-densities-for-smc">
<span id="simple-example-pdf-family"></span><h3>Defining a family of probability densities for SMC<a class="headerlink" href="#defining-a-family-of-probability-densities-for-smc" title="Permalink to this headline">¶</a></h3>
<p>Remember that our goal is to sample <a href="#equation-simple_model_pdf">(6)</a> using SMC. Towards
this goal we need to define a one-parameter family of probability densities
<a href="#equation-p_gamma">(5)</a> starting from a simple one to our target. The simplest choice
is probably this:</p>
<div class="math" id="equation-simple_model_pdf_family">
<p><span class="eqno">(7)</span><img src="_images/math/a95d4c0d64c6bc8592324649f4b620da476f9182.png" alt="\pi_{\gamma}(x) = p^{\gamma}(x)."/></p>
</div><p>Notice that: 1) for <img class="math" src="_images/math/e2ce879a30de26bdc81e97a97a4df4021567c568.png" alt="\gamma=1"/> we obtain <img class="math" src="_images/math/c79e42f2816f4adb7d6b8ac8344d7e37fc7533e4.png" alt="p_\gamma(x)"/> and 2) for
<img class="math" src="_images/math/66981fa3920210c6ad8dbe5e968783d5dd7520c3.png" alt="\gamma"/> small (say <img class="math" src="_images/math/7fe07176ed9974e8b19dcfbd381079d5ef313ce3.png" alt="\gamma=10^{-2}"/>) we obtain a relatively flat
probability density. See <a class="reference internal" href="#simple-example-family-of-pdf-s-figure">Simple Example Family of PDF&#8217;s Figure</a>.</p>
<div class="figure align-center" id="simple-example-family-of-pdf-s-figure">
<img alt="_images/simple_model_pdf_family.png" src="_images/simple_model_pdf_family.png" />
<p class="caption">Plot of <img class="math" src="_images/math/c884d212f2d5c97264410933a8ae10b6625699f2.png" alt="\pi_\gamma(x)"/> of <a href="#equation-simple_model_pdf_family">(7)</a> for
various <img class="math" src="_images/math/66981fa3920210c6ad8dbe5e968783d5dd7520c3.png" alt="\gamma"/>&#8216;s.</p>
</div>
</div>
<div class="section" id="defining-a-pymc-model">
<span id="simple-example-model"></span><h3>Defining a <a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a> model<a class="headerlink" href="#defining-a-pymc-model" title="Permalink to this headline">¶</a></h3>
<p>Since, this is our very first example we will use it as an opportunity to show
how <a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a> can be used to define probabilistic models as well as MCMC sampling
algorithms. First of all let us mention that a <cite>PyMC</cite> model has to be packaged
either in a class or in a module. For the simple example we are considering, we
choose to use the module approach (see
<a class="reference download internal" href="_downloads/simple_model.py"><tt class="xref download docutils literal"><span class="pre">examples/simple_model.py</span></tt></a>).
The model can be trivially defined using <cite>PyMC</cite> decorators. All we
have to do is define the logarithm of <img class="math" src="_images/math/dc5f7d7147bbf82d26410853917905ad1e834ea1.png" alt="\pi_{\gamma}(x)"/>. We will call it
<tt class="docutils literal"><span class="pre">mixture</span></tt>. The contents of that module are:</p>
<div class="highlight-python"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40</pre></div></td><td class="code"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">pymc</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="nd">@pymc.stochastic</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="hll"><span class="k">def</span> <span class="nf">mixture</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">pi</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">],</span> <span class="n">mu</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">],</span>
</span><span class="hll">        <span class="n">sigma</span><span class="o">=</span><span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]):</span>
</span>    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The log probability of a mixture of normal densities.</span>

<span class="sd">    :param value:       The point of evaluation.</span>
<span class="sd">    :type value :       float</span>
<span class="sd">    :param gamma:       The parameter characterizing the SMC one-parameter</span>
<span class="sd">                        family.</span>
<span class="sd">    :type gamma :       float</span>
<span class="sd">    :param pi   :       The weights of the components.</span>
<span class="sd">    :type pi    :       1D :class:`numpy.ndarray`</span>
<span class="sd">    :param mu   :       The mean of each component.</span>
<span class="sd">    :type mu    :       1D :class:`numpy.ndarray`</span>
<span class="sd">    :param sigma:       The standard deviation of each component.</span>
<span class="sd">    :type sigma :       1D :class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># Make sure everything is a numpy array</span>
    <span class="n">pi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">mu</span><span class="p">)</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sigma</span><span class="p">)</span>
    <span class="c"># The number of components in the mixture</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">pi</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="c"># pymc.normal_like requires the precision not the variance:</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="c"># The following looks a little bit awkward because of the need for</span>
    <span class="c"># numerical stability:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">pi</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">pymc</span><span class="o">.</span><span class="n">normal_like</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">mu</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">tau</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
                      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">fsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
    <span class="c"># logp should never be negative, but it can be zero...</span>
    <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;=</span> <span class="mf">0.</span><span class="p">:</span>
        <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="k">return</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</td></tr></table></div>
<p>This might look a little bit complicated but unfortunately one has to take care
of round-off errors when sump small numbers...
Notice that, we have defined pretty much every part of the mixture as an
independent variable. The essential variable that defines the family of
<a href="#equation-simple_model_pdf_family">(7)</a> is <tt class="docutils literal"><span class="pre">gamma</span></tt>. Well, you don&#8217;t actually have to
call it <tt class="docutils literal"><span class="pre">gamma</span></tt>, but we will talk about this later...</p>
<p>Let&#8217;s import that module and see what we can do with it:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">simple_model</span> <span class="kn">as</span> <span class="nn">model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">parents</span>
<span class="go">{&#39;mu&#39;: [-1.0, 2.0], &#39;pi&#39;: [0.2, 0.8], &#39;sigma&#39;: [0.01, 0.01], &#39;gamma&#39;: 1.0}</span>
</pre></div>
</div>
<p>The final command shows you all the parents of the stochastic variable
<tt class="docutils literal"><span class="pre">mixture</span></tt>.
The stochastic variable mixture was assigned a value by default (see line 4
at the code block above). You can see the current value of the stochastic
variable at any time by doing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">value</span>
<span class="go">1.0</span>
</pre></div>
</div>
<p>If we started a <cite>MCMC</cite> chain at this point, this would be the initial value of
the chain. You can change it to anything you want by simply doing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">value</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p>To see the logarithm of the probability at the current state of the stochastic
variable, do:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">logp</span>
<span class="go">-111.11635344</span>
</pre></div>
</div>
<p>Now, if you want to change, let&#8217;s say, <tt class="docutils literal"><span class="pre">gamma</span></tt> to <tt class="docutils literal"><span class="pre">0.5</span></tt> all
you have to do is:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">parents</span><span class="p">[</span><span class="s">&#39;gamma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">gamma</span>
<span class="go">0.5</span>
</pre></div>
</div>
<p>The logarithm of the probability should have changed also:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">model</span><span class="o">.</span><span class="n">mixture</span><span class="o">.</span><span class="n">logp</span>
<span class="go">-55.5581767201</span>
</pre></div>
</div>
</div>
<div class="section" id="attempting-to-do-mcmc">
<span id="mcmc-attempt"></span><h3>Attempting to do <a class="reference external" href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a><a class="headerlink" href="#attempting-to-do-mcmc" title="Permalink to this headline">¶</a></h3>
<p>Let&#8217;s load the model again and attempt to do <a class="reference external" href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> using <a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a>&#8216;s
functionality:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">simple_model</span> <span class="kn">as</span> <span class="nn">model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pymc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mcmc_sampler</span> <span class="o">=</span> <span class="n">pymc</span><span class="o">.</span><span class="n">MCMC</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mcmc_sampler</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">burn</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>You should see a progress bar measuring the number of samples taken. It should
take about a minute to finish. We are actually doing <img class="math" src="_images/math/5d09267a29bc4ec950a006fe23bfb45f7700b680.png" alt="10^6"/> <a class="reference external" href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> steps,
we burn the first <tt class="docutils literal"><span class="pre">burn</span> <span class="pre">=</span> <span class="pre">1000</span></tt> samples and we are looking at the chain
every <tt class="docutils literal"><span class="pre">thin</span> <span class="pre">=</span> <span class="pre">1000</span></tt> samples (i.e., we are dropping everything in between).
<a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a> automatically picks a proposal (see <a class="reference external" href="http://pymc-devs.github.io/pymc/extending.html#user-defined-step-methods">MCMC step methods</a>) for you. For
this particular example it should have picked
<tt class="xref py py-class docutils literal"><span class="pre">pymc.step_methods.Metropolis</span></tt> which corresponds to a simple random walk
proposal. There is no need to tune the parameters of the random walk since
<a class="reference external" href="http://pymc-devs.github.io/pymc/">PyMC</a> is supposed to do that for you. In any case, it is possible to find the
right variance for the random walk, but you need to know exactly how far apart
the modes are...</p>
<p>You may look at the samples we&#8217;ve got by doing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span> <span class="n">mcmc_sampler</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="s">&#39;mixture&#39;</span><span class="p">)[:]</span>
<span class="go">[ 1.9915846   1.93300521  2.09291872  2.05159841  2.06620882  1.88901709</span>
<span class="go">  1.89521431  1.9631256   2.0363258   1.9756637   2.04818845  1.85036634</span>
<span class="go">  1.98907666  1.82212356  1.97678175  1.99854311  1.92124829  2.02077581</span>
<span class="go">  2.08536334  2.16664208  2.08328293  2.05378638  1.89437676  2.09555348</span>
<span class="gp">...</span>
</pre></div>
</div>
<p>Now, let us plot the results:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pymc</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mcmc_sampler</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The results are shown in <a class="reference internal" href="#simple-example-mcmc-figure">Simple Example MCMC Figure</a>. Unless, you are
extremely lucky, you should have missed one of the modes...</p>
<div class="figure align-center" id="simple-example-mcmc-figure">
<img alt="_images/simple_model_mcmc.png" src="_images/simple_model_mcmc.png" />
</div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Tutorial</a><ul>
<li><a class="reference internal" href="#what-is-sequential-monte-carlo">What is Sequential Monte Carlo?</a></li>
<li><a class="reference internal" href="#what-is-implemented-in-pysmc">What is implemented in <tt class="docutils literal"><span class="pre">pysmc</span></tt>?</a></li>
<li><a class="reference internal" href="#a-simple-example">A Simple Example</a><ul>
<li><a class="reference internal" href="#defining-a-family-of-probability-densities-for-smc">Defining a family of probability densities for SMC</a></li>
<li><a class="reference internal" href="#defining-a-pymc-model">Defining a PyMC model</a></li>
<li><a class="reference internal" href="#attempting-to-do-mcmc">Attempting to do MCMC</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="install.html"
                        title="previous chapter">Installation</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="reference.html"
                        title="next chapter">Reference</a></p>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="reference.html" title="Reference"
             >next</a> |</li>
        <li class="right" >
          <a href="install.html" title="Installation"
             >previous</a> |</li>
        <li><a href="index.html">pysmc 0.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2013, Ilias Bilionis.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2b2.
    </div>
  </body>
</html>